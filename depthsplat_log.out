/work/courses/3dv/35/envs/depthsplat/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/work/courses/3dv/35/envs/depthsplat/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
[36mSaving outputs to checkpoints/re10k-256x256-depthsplat-small.[39m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Using cache found in /home/maqima/.cache/torch/hub/facebookresearch_dinov2_main
[2025-05-31 19:04:46,080][dinov2][INFO] - using MLP layer as FFN
wandb: Currently logged in as: seamoon2020 (seamoon2020-eth-z-rich). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.7
wandb: Run data is saved locally in checkpoints/re10k-256x256-depthsplat-small/wandb/run-20250531_190504-bcc7uqzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run re10k-256x256-depthsplat-small
wandb: ‚≠êÔ∏è View project at https://wandb.ai/seamoon2020-eth-z-rich/depthsplat
wandb: üöÄ View run at https://wandb.ai/seamoon2020-eth-z-rich/depthsplat/runs/bcc7uqzg
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type                 | Params | Mode 
------------------------------------------------------------
0 | encoder    | EncoderDepthSplat    | 38.4 M | train
1 | decoder    | DecoderSplattingCUDA | 0      | train
2 | losses     | ModuleList           | 0      | train
3 | roma_model | RegressionMatcher    | 111 M  | train
------------------------------------------------------------
126 M     Trainable params
23.1 M    Non-trainable params
149 M     Total params
598.577   Total estimated model params size (MB)
1139      Modules in train mode
59        Modules in eval mode
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /work/courses/3dv/35/envs/depthsplat/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
Using coarse resolution (560, 560), and upsample res (864, 864)
train: 1308
val: 1
test: 7286
Froze: encoder.depth_predictor.backbone.conv1.weight
Froze: encoder.depth_predictor.backbone.layer1.0.conv1.weight
Froze: encoder.depth_predictor.backbone.layer1.0.conv2.weight
Froze: encoder.depth_predictor.backbone.layer1.1.conv1.weight
Froze: encoder.depth_predictor.backbone.layer1.1.conv2.weight
Froze: encoder.depth_predictor.backbone.layer2.0.conv1.weight
Froze: encoder.depth_predictor.backbone.layer2.0.conv2.weight
Froze: encoder.depth_predictor.backbone.layer2.0.downsample.0.weight
Froze: encoder.depth_predictor.backbone.layer2.0.downsample.0.bias
Froze: encoder.depth_predictor.backbone.layer2.1.conv1.weight
Froze: encoder.depth_predictor.backbone.layer2.1.conv2.weight
Froze: encoder.depth_predictor.backbone.layer3.0.conv1.weight
Froze: encoder.depth_predictor.backbone.layer3.0.conv2.weight
Froze: encoder.depth_predictor.backbone.layer3.0.downsample.0.weight
Froze: encoder.depth_predictor.backbone.layer3.0.downsample.0.bias
Froze: encoder.depth_predictor.backbone.layer3.1.conv1.weight
Froze: encoder.depth_predictor.backbone.layer3.1.conv2.weight
Froze: encoder.depth_predictor.backbone.conv2.weight
Froze: encoder.depth_predictor.backbone.conv2.bias
Froze: encoder.depth_predictor.pretrained.cls_token
Froze: encoder.depth_predictor.pretrained.pos_embed
Froze: encoder.depth_predictor.pretrained.patch_embed.proj.weight
Froze: encoder.depth_predictor.pretrained.patch_embed.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.0.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.0.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.0.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.0.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.0.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.0.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.0.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.0.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.0.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.0.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.0.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.0.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.0.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.0.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.1.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.1.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.1.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.1.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.1.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.1.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.1.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.1.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.1.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.1.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.1.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.1.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.1.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.1.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.2.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.2.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.2.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.2.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.2.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.2.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.2.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.2.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.2.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.2.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.2.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.2.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.2.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.2.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.3.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.3.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.3.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.3.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.3.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.3.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.3.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.3.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.3.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.3.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.3.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.3.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.3.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.3.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.4.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.4.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.4.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.4.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.4.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.4.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.4.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.4.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.4.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.4.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.4.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.4.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.4.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.4.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.5.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.5.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.5.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.5.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.5.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.5.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.5.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.5.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.5.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.5.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.5.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.5.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.5.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.5.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.6.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.6.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.6.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.6.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.6.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.6.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.6.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.6.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.6.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.6.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.6.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.6.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.6.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.6.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.7.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.7.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.7.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.7.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.7.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.7.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.7.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.7.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.7.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.7.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.7.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.7.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.7.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.7.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.8.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.8.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.8.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.8.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.8.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.8.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.8.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.8.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.8.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.8.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.8.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.8.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.8.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.8.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.9.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.9.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.9.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.9.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.9.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.9.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.9.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.9.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.9.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.9.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.9.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.9.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.9.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.9.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.10.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.10.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.10.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.10.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.10.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.10.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.10.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.10.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.10.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.10.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.10.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.10.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.10.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.10.ls2.gamma
Froze: encoder.depth_predictor.pretrained.blocks.11.norm1.weight
Froze: encoder.depth_predictor.pretrained.blocks.11.norm1.bias
Froze: encoder.depth_predictor.pretrained.blocks.11.attn.qkv.weight
Froze: encoder.depth_predictor.pretrained.blocks.11.attn.qkv.bias
Froze: encoder.depth_predictor.pretrained.blocks.11.attn.proj.weight
Froze: encoder.depth_predictor.pretrained.blocks.11.attn.proj.bias
Froze: encoder.depth_predictor.pretrained.blocks.11.ls1.gamma
Froze: encoder.depth_predictor.pretrained.blocks.11.norm2.weight
Froze: encoder.depth_predictor.pretrained.blocks.11.norm2.bias
Froze: encoder.depth_predictor.pretrained.blocks.11.mlp.fc1.weight
Froze: encoder.depth_predictor.pretrained.blocks.11.mlp.fc1.bias
Froze: encoder.depth_predictor.pretrained.blocks.11.mlp.fc2.weight
Froze: encoder.depth_predictor.pretrained.blocks.11.mlp.fc2.bias
Froze: encoder.depth_predictor.pretrained.blocks.11.ls2.gamma
Froze: encoder.depth_predictor.pretrained.norm.weight
Froze: encoder.depth_predictor.pretrained.norm.bias
[36mLoaded pretrained weights: pretrained/depthsplat-gs-small-re10k-256x256-view2-cfeab6b1.pth[39m
validation step 0; scene = ['306e2b7785657539']; context = [[14, 44]]
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /work/courses/3dv/35/envs/depthsplat/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
EncoderDepthSplat(
  (depth_predictor): MultiViewUniMatch(
    (backbone): CNNEncoder(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (relu1): ReLU(inplace=True)
      (layer1): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (relu): ReLU(inplace=True)
          (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
        (1): ResidualBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (relu): ReLU(inplace=True)
          (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (layer2): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (relu): ReLU(inplace=True)
          (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (downsample): Sequential(
            (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))
            (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): ResidualBlock(
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (relu): ReLU(inplace=True)
          (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (layer3): Sequential(
        (0): ResidualBlock(
          (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (relu): ReLU(inplace=True)
          (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (downsample): Sequential(
            (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))
            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): ResidualBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (relu): ReLU(inplace=True)
          (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    )
    (transformer): MultiViewFeatureTransformer(
      (layers): ModuleList(
        (0-5): 6 x TransformerBlock(
          (self_attn): TransformerLayer(
            (q_proj): Linear(in_features=128, out_features=128, bias=False)
            (k_proj): Linear(in_features=128, out_features=128, bias=False)
            (v_proj): Linear(in_features=128, out_features=128, bias=False)
            (merge): Linear(in_features=128, out_features=128, bias=False)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (cross_attn_ffn): TransformerLayer(
            (q_proj): Linear(in_features=128, out_features=128, bias=False)
            (k_proj): Linear(in_features=128, out_features=128, bias=False)
            (v_proj): Linear(in_features=128, out_features=128, bias=False)
            (merge): Linear(in_features=128, out_features=128, bias=False)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (0): Linear(in_features=256, out_features=1024, bias=False)
              (1): GELU(approximate='none')
              (2): Linear(in_features=1024, out_features=128, bias=False)
            )
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (pretrained): DinoVisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))
        (norm): Identity()
      )
      (blocks): ModuleList(
        (0-11): 12 x NestedTensorBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MemEffAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
      )
      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (head): Identity()
    )
    (regressor): ModuleList(
      (0): Sequential(
        (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GroupNorm(8, 128, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): UNetModel(
          (input_blocks): ModuleList(
            (0): Sequential(
              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
            (1): Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Identity()
              )
            )
            (2): Sequential(
              (0): Downsample(
                (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              )
            )
            (3): Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Identity()
              )
            )
            (4): Sequential(
              (0): Downsample(
                (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
              )
            )
            (5): Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Identity()
              )
              (1): AttentionBlock(
                (qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,))
                (attention): QKVAttentionLegacy()
                (norm): GroupNorm8(8, 128, eps=1e-05, affine=True)
                (proj_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
              )
            )
          )
          (middle_block): Sequential(
            (0): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (out_layers): Sequential(
                (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
            (1): Identity()
            (2): ResBlock(
              (in_layers): Sequential(
                (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (h_upd): Identity()
              (x_upd): Identity()
              (out_layers): Sequential(
                (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                (1): SiLU()
                (2): Dropout(p=0, inplace=False)
                (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
              (skip_connection): Identity()
            )
          )
          (output_blocks): ModuleList(
            (0): Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 256, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
              )
              (1): AttentionBlock(
                (qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,))
                (attention): QKVAttentionLegacy()
                (norm): GroupNorm8(8, 128, eps=1e-05, affine=True)
                (proj_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
              )
            )
            (1): Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 256, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
              )
              (1): AttentionBlock(
                (qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,))
                (attention): QKVAttentionLegacy()
                (norm): GroupNorm8(8, 128, eps=1e-05, affine=True)
                (proj_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
              )
              (2): Upsample(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
            )
            (2): Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 256, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
              )
            )
            (3): Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 256, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
              )
              (1): Upsample(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              )
            )
            (4-5): 2 x Sequential(
              (0): ResBlock(
                (in_layers): Sequential(
                  (0): GroupNorm8(8, 256, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (h_upd): Identity()
                (x_upd): Identity()
                (out_layers): Sequential(
                  (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
                  (1): SiLU()
                  (2): Dropout(p=0, inplace=False)
                  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
                )
                (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
              )
            )
          )
          (out): Sequential(
            (0): GroupNorm8(8, 128, eps=1e-05, affine=True)
            (1): SiLU()
            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (regressor_residual): ModuleList(
      (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))
    )
    (depth_head): ModuleList(
      (0): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): GELU(approximate='none')
        (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
      )
    )
    (upsampler): DPTHead(
      (concat_projects): ModuleList(
        (0): Conv2d(208, 48, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(353, 96, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
      )
      (projects): ModuleList(
        (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))
        (3): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
      )
      (resize_layers): ModuleList(
        (0): ConvTranspose2d(48, 48, kernel_size=(4, 4), stride=(4, 4))
        (1): ConvTranspose2d(96, 96, kernel_size=(2, 2), stride=(2, 2))
        (2): Identity()
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (scratch): Module(
        (layer1_rn): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (layer2_rn): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (layer3_rn): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (layer4_rn): Conv2d(384, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (refinenet1): FeatureFusionBlock(
          (out_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (resConfUnit1): ResidualConvUnit(
            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (activation): ReLU()
            (skip_add): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (resConfUnit2): ResidualConvUnit(
            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (activation): ReLU()
            (skip_add): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (refinenet2): FeatureFusionBlock(
          (out_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (resConfUnit1): ResidualConvUnit(
            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (activation): ReLU()
            (skip_add): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (resConfUnit2): ResidualConvUnit(
            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (activation): ReLU()
            (skip_add): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (refinenet3): FeatureFusionBlock(
          (out_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (resConfUnit1): ResidualConvUnit(
            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (activation): ReLU()
            (skip_add): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (resConfUnit2): ResidualConvUnit(
            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (activation): ReLU()
            (skip_add): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (refinenet4): FeatureFusionBlock(
          (out_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (resConfUnit2): ResidualConvUnit(
            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (activation): ReLU()
            (skip_add): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (output_conv): Sequential(
          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (1): GELU(approximate='none')
          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (3): GELU(approximate='none')
          (4): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (feature_upsampler): DPTHead(
    (concat_projects): ModuleList(
      (0): Conv2d(208, 48, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(352, 96, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (projects): ModuleList(
      (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))
      (3): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (resize_layers): ModuleList(
      (0): ConvTranspose2d(48, 48, kernel_size=(4, 4), stride=(4, 4))
      (1): ConvTranspose2d(96, 96, kernel_size=(2, 2), stride=(2, 2))
      (2): Identity()
      (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (scratch): Module(
      (layer1_rn): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (layer2_rn): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (layer3_rn): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (layer4_rn): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (refinenet1): FeatureFusionBlock(
        (out_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        (resConfUnit1): ResidualConvUnit(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (activation): ReLU()
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (resConfUnit2): ResidualConvUnit(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (activation): ReLU()
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (skip_add): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (refinenet2): FeatureFusionBlock(
        (out_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        (resConfUnit1): ResidualConvUnit(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (activation): ReLU()
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (resConfUnit2): ResidualConvUnit(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (activation): ReLU()
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (skip_add): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (refinenet3): FeatureFusionBlock(
        (out_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        (resConfUnit1): ResidualConvUnit(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (activation): ReLU()
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (resConfUnit2): ResidualConvUnit(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (activation): ReLU()
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (skip_add): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
      (refinenet4): FeatureFusionBlock(
        (out_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        (resConfUnit2): ResidualConvUnit(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (activation): ReLU()
          (skip_add): FloatFunctional(
            (activation_post_process): Identity()
          )
        )
        (skip_add): FloatFunctional(
          (activation_post_process): Identity()
        )
      )
    )
  )
  (gaussian_adapter): GaussianAdapter()
  (pose_adjuster): PoseAdjustHead(
    (global_pool): AdaptiveAvgPool2d(output_size=1)
    (fc): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=64, out_features=128, bias=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=9, bias=True)
    )
  )
  (gaussian_regressor): Sequential(
    (0): Conv2d(69, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): GELU(approximate='none')
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (gaussian_head): Sequential(
    (0): Conv2d(132, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
    (1): GELU(approximate='none')
    (2): Conv2d(37, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
  )
)
